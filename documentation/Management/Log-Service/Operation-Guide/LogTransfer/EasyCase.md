## Log Dump Configuration - ALB Access Log Dump

The section specifies how to complete configuration of one log dump via a true case. It aims to describe the complete configuration process, making users easily understand log dump function.

### I. Dump Requirement Scenario:

1. I purchase an ALB on JD Cloud, and want to automatically store the access logs of ALB into my OSS bucket, so that I can download the log data later, process and analyze the response time, and conduct monitoring statistics on the user side.

2. View the execution status of some log data dump.

### II. Dump Task Setting:

The following actions are required to complete the above dump configuration requirements:

1. Purchase the ALB service on JD Cloud and open a log service, create a log set (myAppVersion1) under the log service, and then create a log subject (alblog) and collection configuration under the log set to add the purchased ALB to the collection instance and collect the log. The purchased ALB will generate the access log.

2. Select the log set (myAppVersion1) and log subject (alblog) of the business application log, click **Dump Configuration** behind the alblog log subject, and enter the dump configuration page.

![](https://raw.githubusercontent.com/jdcloudcom/cn/zhangwenjie-only/image/LogService/LogTransfer/case01.jpg)

3. Click **Create Dump Task** and start configuration.

![](https://raw.githubusercontent.com/jdcloudcom/cn/zhangwenjie-only/image/LogService/LogTransfer/case02.jpg)

4. Enter the dump task name: **ALB Access Log Dump**.

5. Dump object, that is, dump it to the OSS, select the dump bucket **logshipper-test-10** under my account. The access log generated by ALB will be dumped into the dump bucket, then I can select the dump bucket in the OSS page and download the dumped log data to the local. OSS charges based on the data bulk dumped and how long it had been stored.

6. Enter the directory prefix: **myappversion1/**. When dumped, the ALB access long will be dumped to the directory.

7. Enter the partition format: **%Y/%m/%d**. When dumped, directories will be automatically outputted according to strptime time formatting in the format of year/month/day, for example: 08/08/2019.

8. Dump file size: select **500MB** based on my own needs. A single log file larger than 500MB will be split into files with each no larger than 500MB each.

9. Dump time interval: select **30min** based on my own needs. Every 30 minutes, the generated log files in the corresponding period are dumped to the selected dump object.

10. To easily view what each field in the access log represents, the dump format **JSON** is selected.

11. To save the storage cost of OSS, the log files are compressed and the compression format is **gzip**.

![](https://raw.githubusercontent.com/jdcloudcom/cn/zhangwenjie-only/image/LogService/LogTransfer/case03.jpg)

### II. View Dump Task History:

After the dump task is created, its execution history and status can be viewed. For failed dump tasks, retry is supported within one hour:

1. Click **Dump Task History** in the left menu bar of the log service to enter the dump task history page, and select the log set (myAppVersion1), log subject (alblog) and dump task (myappversion1). Or click dump **Dump History** behind the **myappversion1** task in the dump configuration page. To view the dump history of **myappversion1**.

2. After selecting a search range for nearly one hour based on the requirement, one of the task dumps is found failed. But it is still within one hour, so retry is supported. Click **Try Again** and dump again.

















