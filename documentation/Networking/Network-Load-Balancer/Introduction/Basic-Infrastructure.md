# Basic architecture

Network load balancer is a self-developed product by JD Cloud & AI, and focuses on four layers business services. It supports high performance, low latency, session persistence, etc. for over 100 million concurrent connections and millions of new connections per second. NLB supports auto scaling, and can eliminate the cumber of user’s business planning and manual expansion; NLB supports deployment across multiple availability zones and works closely with availability group AG to meet high availability deployment needs;

The network load balancer can distribute large concurrent traffic to several backend instances, adjust resource utilization, eliminate influence to systems by fault of single device, improve system availability and expand system serviceability.

![京东智联云私有网络业务架构](../../../../image/Networking/NLB/NLB-VPC-Arch.png)

## Provide high-availability service with multiple guarantees

JD Cloud & AI load balancer can realize high availability of multi-mechanism guarantee service:



- High availability of load balancer



1. Multiple availability zone deployment: For the region supporting multiple availability zones, the load balancer instances can be deployed under several availability zones according to the business demand. Once the machine room of the availability zone fails or the resource under the availability zone fails, the traffic can be automatically forwarded to other availability zones, to realize the high availability of availability zones;
2. Resource redundancy mechanism: As the load balancer adopts the cluster deployment, it can provide the active-active mode (at least 2 resource instances are provided under a single availability zone). For example, in one load balancer service fails, the traffic can be automatically forwarded to another load balancer, without being detected by the business side.



- High availability of backend server

The load balancer can be associated to the availability group and dynamically adjust server count depending on business traffic and device load situation, so as to realize reasonable distribution of resources and guarantee normal operation of business.

The NLB high availability architecture is as follows:
![NLB高可用架构](../../../../image/Networking/NLB/NLB-HA.png)

# Business Architecture

The structure of NLB products is as follows:
![NLB产品结构](../../../../image/Networking/NLB/NLB-Arch.png)




Component of network load balancer (NLB)



- Load Balancer Instance

Before using the load balancer service, it needs to purchase, create load balancer instance, one load balancer instance can be set up with multiple listeners, multiple backend services, multiple virtual server groups, and can be attached with multiple availability groups.



- Listener

Before performing traffic loading, it needs to set up at least one listener, designate the listening protocol/port et.



- Backend Service

It is used for providing management module for forwarding, scheduling policy from load balancer to backend server, including forwarding protocol/port, scheduling algorithm, session persistence and forwarding backend server, etc.



- Virtual Server Group

A set of VM or container resources receiving access request is managed by the virtual server group. The virtual server group can be combined with auto scaling for use so as to realize auto expansion and contraction of VM, but the dispersion capacity of machine of AS is relatively weak, paying no attention to high availability dispersion mechanism across rack dimensions.



- Availability Group

Availability Group is the Virtual Machine logic set provided by JD Cloud & AI, which may support auto scaling across racks, across AZ according to the machine template designated by the user so as to distribute Virtual Machines in dispersion to the physical resources separately isolated. When hardware or power failure occurs, only the Virtual Machines in Availability Group can be affected, the business is still in available status.

## High reusability architecture description

- Listeners in the multiple same protocol types but under different server port numbers can be set under one load balancer;

- Multiple listeners under the same load balancer can be reused to associate with the same backend service;

- Multiple backend services under the same load balancer can be reused to associate with the same backend server group/availability group;

- The same virtual server (machine/container) can be registered to the same virtual server group through different ports;

- The same virtual server (machine/container) can be registered to different virtual server groups;

- The same availability group can be attached to multiple backend services of the same load balancer;

- The same availability group can be attached to backend services of multiple load balancers.

Remark:

The virtual server group can be only added with servers that are on the same Virtual Private Cloud as the associated load balancer instance.

# Key technical principle

## Shunting principles

An external access request is distributed to the backend server by the load balancer instance according to the relevant policies and forwarding rules for processing. At present, the shunting type supported by the Load Balancer includes: weighted round robin, weighting least connection and weighted source IP. Round robin means distributing connection request one by one by order to the backend service instance, weighted round robin means distributing the round times according to the weight ratio of instance. The least connection distributes requests according to the minimum number of active connections between load balancer and each backend service instance, the weighted least connection finally guarantees the ratio of the number of active connections between load balancer and backend services to be consistent with the weight ratio. Source IP is to hash according to the requested source IP addresses where requests of the same source IP will be distributed to the same backend service instance for processing. Weighted source IP is to guarantee that the proportion of the source IP count corresponding to the backend service instance distributed by the Load Balancer in all of the requested source IP count is consistent with the weight ratio.

## Session persistence principles

Session persistence is also called as Sticky Sessions or Session affinity. Session persistence means a functional mechanism on the load balancer, which distributes data while guaranteeing that relevant access requests from the same client can be distributed to the same server.

![NLB Session Persistence Principles](../../../../image/Networking/NLB/NLB-SessionSticky-Therory.png)

## Connection draining principle

Connection draining is a way for load balancer registration instances to gracefully exit the service. When a backend instance (virtual machine or container) is unregistered from the backend service, load balancer stops sending new connection requests to the exiting instance and maintains the connected service status until the connection draining timer expires.
![NLB Connection Draining Principle](../../../../image/Networking/NLB/NLB-ConnectionDraining1-Therory.png)
![NLB Connection Draining Principle](../../../../image/Networking/NLB/NLB-ConnectionDraining2-Therory.png)

## Relevant References

- [Product advantage](../Introduction/Benefits.md)
- [Product function](../Introduction/Features.md)
- [Price overview](../Pricing/Price-Overview.md)
- [Billing rules](../Pricing/Billing-Rules.md)
- [Create Instance](../Getting-Started/Create-Instance.md)
- [Create virtual server group](../Operation-Guide/TargetGroup-Management.md)
- [Configure listening policy](../Operation-Guide/Listener-Management.md)
- [Manage rear end service and view health status of service instance](../Operation-Guide/Backend-Management.md)
- [View monitoring information](../Operation-Guide/Monitoring.md)



